{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Bài tập 4\n",
            "\n",
            "\n",
            "Triệu Nhật Minh - 21127112\n",
            "\n",
            "---"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Import necessary libraries"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import math\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Generalization Error"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The VC bound is given by:\n",
            "\n",
            "$$\n",
            "N \\geq \\frac{8}{\\epsilon^2} \\ln (\\frac{4m_H(2N)}{\\delta})\n",
            "$$\n",
            "\n",
            "The approximation bound is given by: $m_H(N) \\approx N^{d_{\\text{VC}}}$\n",
            "\n",
            "$$\n",
            "\\Rightarrow N \\geq \\frac{8}{\\epsilon^2} \\ln (\\frac{4(2N)^{d_{\\text{VC}}}}{\\delta})\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\epsilon \\leq \\sqrt{\\frac{8}{N} \\ln (\\frac{4(2N)^{d_{\\text{VC}}}}{\\delta})}\n",
            "$$\n",
            "\n",
            "We have $d_{\\text{VC}} = 10$, $\\delta = 1 - 0.95 = 0.05$, $\\epsilon = 0.05$.\n",
            "\n",
            "We need to find $N$ such that:\n",
            "\n",
            "$$\n",
            "0.05 \\leq \\sqrt{\\frac{8}{N} \\ln (\\frac{4(2N)^{10}}{0.05})}\n",
            "$$"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def solve_numerical_approx(dVC, delta, epsilon):\n",
            "    \"\"\"\n",
            "    Find the closest numerical approximation of sample size N.\n",
            "\n",
            "    Args:\n",
            "        dVC (int): VC dimension\n",
            "        delta (float): confidence level\n",
            "        epsilon (float): generalization error\n",
            "    \"\"\"\n",
            "    const = 8 / epsilon**2\n",
            "    threshold = 1\n",
            "    \n",
            "    N = 400000  # Initial guess since all N >= 400000\n",
            "    N_prev = 0\n",
            "    \n",
            "    while abs(N - N_prev) >= threshold:\n",
            "        N_prev = N\n",
            "        N = const * math.log((4 * ((2 * N_prev)**dVC)) / delta)\n",
            "    \n",
            "    return N"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "solve_numerical_approx(10, 0.05, 0.05)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[1] The correct answer is [d] 460 000."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 2."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Since $d_{\\text{VC}} = 50$, we have $N > d_{\\text{VC}}$. Therefore, we can use the approximation bound:\n",
            "\n",
            "$$\n",
            "m_H(N) = N^{d_{\\text{VC}}}\n",
            "$$"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Implement the bound functions\n",
            "\n",
            "def mH(N, dVC):\n",
            "    return np.float64(np.exp(dVC * np.log(np.float64(N)))) # N^dVC = e^(dVC * log(N)), N is float64 to avoid overflow\n",
            "\n",
            "def original_VC(N, dVC, delta):\n",
            "    return np.sqrt((8/N) * np.log(4 * mH(2*N, dVC) / delta))\n",
            "\n",
            "def rademacher_penalty(N, dVC, delta):\n",
            "    return np.sqrt((2 * np.log(2 * N * mH(N, dVC))) / N) + np.sqrt((2/N) * np.log(1/delta)) + (1/N)\n",
            "\n",
            "max_iter = 100\n",
            "\n",
            "def parrondo_van_den_broek(N, dVC, delta):\n",
            "    epsilon = np.ones_like(N)  # initial guess\n",
            "    for _ in range(max_iter):\n",
            "        epsilon_prev = epsilon\n",
            "        epsilon = np.sqrt((1/N) * (2 * epsilon_prev + np.log(6 * mH(2*N, dVC) / delta)))\n",
            "        if np.all(np.abs(epsilon - epsilon_prev) < 0.1):\n",
            "            break\n",
            "    return epsilon\n",
            "\n",
            "def devroye(N, dVC, delta):\n",
            "    epsilon = np.ones_like(N)  # initial guess\n",
            "    for _ in range(max_iter):\n",
            "        epsilon_prev = epsilon\n",
            "        left = 4 * epsilon_prev * (1 + epsilon_prev)\n",
            "        right = np.log(4) + 2 * dVC * np.log(N) - np.log(delta)\n",
            "        epsilon = np.sqrt((1/(2*N)) * (left + right))\n",
            "        if np.all(np.abs(epsilon - epsilon_prev) < 0.1):\n",
            "            break\n",
            "    return epsilon"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "In devration bound, we have:\n",
            "$$\n",
            "\\ln m_H(N^2) = \\ln N^{2d_{\\text{VC}}} = 2d_{\\text{VC}} \\ln N\n",
            "$$\n",
            "\n",
            "By using mathematically transformation, we can handle the large value of $N$."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def solve_smallest_bound_functions(N_start, N_end):\n",
            "    dVC = 50\n",
            "    delta = 0.05\n",
            "    N_values = np.arange(N_start, N_end+1)\n",
            "    \n",
            "    arr_vc = [original_VC(N, dVC, delta) for N in N_values]\n",
            "    arr_rademacher = [rademacher_penalty(N, dVC, delta) for N in N_values]\n",
            "    arr_parrondo = [parrondo_van_den_broek(N, dVC, delta) for N in N_values]\n",
            "    arr_devroye = [devroye(N, dVC, delta) for N in N_values]\n",
            "\n",
            "    plt.plot(N_values, arr_vc, label=\"original VC\")\n",
            "    plt.plot(N_values, arr_rademacher, label=\"rademacher\")\n",
            "    plt.plot(N_values, arr_parrondo, label=\"parrondo\")\n",
            "    plt.plot(N_values, arr_devroye, label=\"devroye\")\n",
            "    \n",
            "    plt.legend()\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "solve_smallest_bound_functions(N_start=500, N_end=10000)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "From this plot, we acknowledge that the Devroye bound is the smallest one.\n",
            "\n",
            "However, let's take a look at the plot with $N_{\\text{start}} = 5000$."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "solve_smallest_bound_functions(N_start=5000, N_end=10000)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[2] The correct answer is [d] Devroye bound: $\\epsilon \\leq \\sqrt{\\frac{1}{2N}(4\\epsilon(1 + \\epsilon) + \\ln (\\frac{4m_H(N^2)}{\\delta}))}$"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 3."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Since $d_{\\text{VC}} = 50$, we have $N < d_{\\text{VC}}$ and the approximation bound is not valid anymore. In this case, we have to use the original growth function:\n",
            "\n",
            "$$\n",
            "m_H(N) = 2^N\n",
            "$$"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def mH(N, dVC):\n",
            "    return 2**(N)\n",
            "\n",
            "def original_VC(N, dVC, delta):\n",
            "    return np.sqrt((8/N) * np.log(4 * mH(2*N, dVC) / delta))\n",
            "\n",
            "def rademacher_penalty(N, dVC, delta):\n",
            "    return np.sqrt((2 * np.log(2 * N * mH(N, dVC))) / N) + np.sqrt((2/N) * np.log(1/delta)) + (1/N)\n",
            "\n",
            "max_iter = 100\n",
            "\n",
            "def parrondo_van_den_broek(N, dVC, delta):\n",
            "    epsilon = np.ones_like(N)  # initial guess\n",
            "    for _ in range(max_iter):\n",
            "        epsilon_prev = epsilon\n",
            "        epsilon = np.sqrt((1/N) * (2 * epsilon_prev + np.log(6 * mH(2*N, dVC) / delta)))\n",
            "        if np.all(np.abs(epsilon - epsilon_prev) < 0.1):\n",
            "            break\n",
            "    return epsilon\n",
            "\n",
            "def devroye(N, dVC, delta):\n",
            "    epsilon = np.ones_like(N)  # initial guess\n",
            "    for _ in range(max_iter):\n",
            "        epsilon_prev = epsilon\n",
            "        left = 4 * epsilon_prev * (1 + epsilon_prev)\n",
            "        right = np.log(4) + 2 * dVC * np.log(N) - np.log(delta)\n",
            "        epsilon = np.sqrt((1/(2*N)) * (left + right))\n",
            "        if np.all(np.abs(epsilon - epsilon_prev) < 0.1):\n",
            "            break\n",
            "    return epsilon"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def solve_smallest_bound_functions_small_N(N_start, N_end):\n",
            "    dVC = 50\n",
            "    delta = 0.05\n",
            "    N_values = np.arange(N_start, N_end+1)\n",
            "    \n",
            "    arr_vc = [original_VC(N, dVC, delta) for N in N_values]\n",
            "    arr_rademacher = [rademacher_penalty(N, dVC, delta) for N in N_values]\n",
            "    arr_parrondo = [parrondo_van_den_broek(N, dVC, delta) for N in N_values]\n",
            "    arr_devroye = [devroye(N, dVC, delta) for N in N_values]\n",
            "\n",
            "    plt.plot(N_values, arr_vc, label=\"original VC\")\n",
            "    plt.plot(N_values, arr_rademacher, label=\"rademacher\")\n",
            "    plt.plot(N_values, arr_parrondo, label=\"parrondo\")\n",
            "    plt.plot(N_values, arr_devroye, label=\"devroye\")\n",
            "    \n",
            "    plt.legend()\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "solve_smallest_bound_functions_small_N(N_start=3, N_end=7)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "With large N, the Devroye bound is the smallest one. However, with small N, the Parrondo and Van den Broek bound is the smallest one.\n",
            "\n",
            "[3] The correct answer is [c] Parrondo and Van den Broek bound: $\\epsilon \\leq \\sqrt{\\frac{1}{N}(2\\epsilon + \\ln (\\frac{6m_H(2N)}{\\delta}))}$"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Bias and Variance"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "$$\n",
            "\\mathbb{E}_{\\mathcal{D}}[(g^{D}(x) - \\bar{g}(x))^2] = \\mathbb{E}_{\\mathcal{D}}[g^{D}(x)^2] - \\mathbb{E}_{\\mathcal{D}}[\\bar{g}(x)^2]\n",
            "$$"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 4."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We can estimate the average function for any $x$ by \n",
            "$$\n",
            "\\bar{g}(x) \\approx \\frac{1}{K} \\sum_{k=1}^{K} g^{D_k}(x)\n",
            "$$ \n",
            "with $g^{D_k}(x)$ denotes the hypothesis function learned from the $k$-th dataset.\n",
            "\n",
            "\n",
            "The given learning model consists of all hypotheses of the form $h(x) = ax$, so we have the transformation of the average function:\n",
            "\n",
            "$$\n",
            "\\bar{g}(x) \\approx \\frac{1}{K} \\sum_{k=1}^{K} g^{D_k}(x)\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\bar{g}(x) \\approx \\frac{1}{K} \\sum_{k=1}^{K} a_k \\cdot x\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\bar{g}(x) \\approx \\frac{1}{K} \\cdot x \\sum_{k=1}^{K} a_k\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\bar{g}(x) \\approx x \\cdot \\hat{a}\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\bar{g}(x) \\approx \\hat{a} \\cdot x\n",
            "$$"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def generate_data(n_samples):\n",
            "    X = np.random.uniform(-1., 1., size=(n_samples, 1))\n",
            "\n",
            "    # Generate N samples from uniform distribution [-1, 1].\n",
            "     \n",
            "    # We use size=(n_samples, 1) in np.random.uniform to generate n_samples samples, each with 1 element. Using size=n_samples would generate a single sample with n_samples elements, which doesn't align with our target function f: [-1, 1] -> R.\n",
            "    \n",
            "    return X\n",
            "\n",
            "def f(x):\n",
            "    return np.sin(np.pi * x)\n",
            "\n",
            "def calculate_coefficient(X, y):\n",
            "    a = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y) # Calculate the optimal coefficient 'a' for the linear hypothesis using the least squares formula.\n",
            "    return a"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Problem 4\n",
            "def solve_expected_hypothesis(n_samples, n_experiments):\n",
            "    a_values = [calculate_coefficient(X, f(X)) for X in (generate_data(n_samples) for _ in range(n_experiments))]\n",
            "    return np.round(np.mean(a_values), 2)\n",
            "\n",
            "n_samples = 2\n",
            "n_experiments = 10000\n",
            "\n",
            "a_hat = solve_expected_hypothesis(n_samples, n_experiments)\n",
            "\n",
            "print(\"g_bar(x) = {}x\".format(a_hat))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[4] The correct answer is the one which has exactly coefficient $\\hat{a}$. Hence [e] is the correct answer because other 4 answers have different coefficients."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 5."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Bias is defined as the difference between the average hypothesis and the target function, shown by the following equation:\n",
            "\n",
            "\n",
            "$$\n",
            "\\text{bias} = E_x \\left(\\bar{g}(x) - f(x) \\right)^2\n",
            "$$\n",
            "\n",
            "Since the target function is $f(x) = \\sin(\\pi x)$, we have:\n",
            "\n",
            "$$\n",
            "\\text{bias} = E_x \\left(\\bar{g}(x) - \\sin(\\pi x) \\right)^2\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\text{bias} = E_x \\left(\\hat{a} \\cdot x - \\sin(\\pi x) \\right)^2\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\text{bias} = \\frac{1}{N} \\sum_{n=1}^{N} \\left(\\hat{a} \\cdot x_n - \\sin(\\pi x_n) \\right)^2\n",
            "$$\n",
            "\n",
            "where $N$ is the number of experiments."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Problem 5\n",
            "def solve_bias(n_experiments):\n",
            "    X = np.random.uniform(-1, 1, n_experiments)\n",
            "    Y = f(X)\n",
            "    g_bar = a_hat * X\n",
            "    bias = np.mean((g_bar - Y)**2)\n",
            "    return bias\n",
            "\n",
            "n_experiments = 10000\n",
            "\n",
            "solve_bias(n_experiments)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[5] The correct answer is [b] 0.3."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 6."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Variances is defined as the difference between the average hypothesis and the target function, shown by the following equation:\n",
            "\n",
            "$$\n",
            "\\text{var} = \\mathbb{E}_{x} \\left[\\mathbb{E}_\\mathcal{D} \\left( g^\\mathcal{D}(x) - \\bar{g}(x) \\right)^2 \\right]\n",
            "$$\n",
            "\n",
            "Since the average hypothesis is $\\bar{g}(x) = \\hat{a} \\cdot x$, we have:\n",
            "\n",
            "$$\n",
            "\\text{var} = \\mathbb{E}_{x} \\left[\\mathbb{E}_\\mathcal{D} \\left( g^\\mathcal{D}(x) - \\hat{a} \\cdot x \\right)^2 \\right]\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\text{var} = \\mathbb{E}_{x} \\left[\\mathbb{E}_\\mathcal{D} \\left( a \\cdot x - \\hat{a} \\cdot x \\right)^2 \\right]\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\text{var} = \\mathbb{E}_{x} \\left[\\mathbb{E}_\\mathcal{D} \\left( (a - \\hat{a}) \\cdot x \\right)^2 \\right]\n",
            "$$\n",
            "\n",
            "$$\n",
            "\\Rightarrow \\text{var} = \\mathbb{E}_{x} \\left[\\mathbb{E}_\\mathcal{D} \\left( (a - \\hat{a})^2 \\cdot x^2 \\right) \\right]\n",
            "$$\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def solve_variance(n_samples, n_experiments):\n",
            "    # Generate all samples and target values\n",
            "    X = np.random.uniform(-1, 1, size=(n_experiments, n_samples, 1))\n",
            "    y = np.array([f(x) for x in X])\n",
            "\n",
            "    # Calculate coefficients 'a' for each experiment\n",
            "    a = np.array([calculate_coefficient(x, y[i]) for i, x in enumerate(X)])\n",
            "\n",
            "    # Calculate hypotheses 'h' for each experiment\n",
            "    h = a * X\n",
            "\n",
            "    # Calculate the expected hypothesis 'g_bar'\n",
            "    g_bar = a_hat * X\n",
            "\n",
            "    # Calculate variances for each experiment\n",
            "    variances = np.mean((h - g_bar)**2, axis=(1, 2)) \n",
            "\n",
            "    # Return the average variance\n",
            "    return np.round(np.mean(variances), 1)\n",
            "\n",
            "n_samples = 2\n",
            "n_experiments = 10000\n",
            "\n",
            "solve_variance(n_samples, n_experiments)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "In this code, the mean of the squared differences `(h - g_bar)**2` is computed for each experiment (represented by the first dimension). This computation is performed across all samples and the third dimension (which is of size 1 here). The outcome is a 1-dimensional array with a length equal to `n_experiments`, where each entry corresponds to the average variance for a specific experiment.\n",
            "\n",
            "At the end, `np.mean(variances)` calculates the average of these computed variances, providing the overall average variance across all experiments.\n",
            "\n",
            "[6] The correct answer is [a] 0.2."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 7."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# VC Dimension"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 8."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "$$\n",
            "m_H(N+1) = 2m_H(N) - \\binom{N}{q}\n",
            "$$\n",
            "\n",
            "with an integer $q \\geq 1$ and $m_H(1) = 2$"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def combination(n, k):\n",
            "    if n < 0 or k < 0:\n",
            "        raise ValueError(\"n and k must be non-negative.\")\n",
            "    return np.float64(math.factorial(n) / (math.factorial(k) * math.factorial(n - k)))\n",
            "\n",
            "def growth_function(N, q):\n",
            "    if N < 1 or q < 1:\n",
            "        raise ValueError(\"N and q must be greater than or equal to 1.\")\n",
            "    \n",
            "    m_H = np.zeros(N + 1)\n",
            "    m_H[1] = 2  # base case\n",
            "\n",
            "    for i in range(2, N + 1):\n",
            "        if i <= q:\n",
            "            m_H[i] = 2 * m_H[i - 1]\n",
            "        else:\n",
            "            m_H[i] = 2 * m_H[i - 1] - combination(i - 1, q)\n",
            "\n",
            "    return m_H[N]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Given that $q \\geq 1$, we'll start our demonstration with a fixed $q = 2$.\n",
            "\n",
            "The VC dimension of a hypothesis set is the greatest value of N for which the growth function $m_H(N)$ equals $2^N$. If $m_H(N+1) < 2^{N+1}$, then the VC dimension is N.\n",
            "\n",
            "The provided growth function is defined recursively as:\n",
            "$$\n",
            "m_H(N + 1) = 2m_H(N) - \\binom{N}{q}\n",
            "$$\n",
            "\n",
            "To find the VC dimension, we need to find the greatest value of N for which $m_H(N) = 2^N$. This is equivalent to finding the smallest value of N for which $m_H(N+1) < 2^{N+1}$.\n",
            "\n",
            "We can achieve this by iterating over values of N, starting from 1, and checking if $m_H(N+1) < 2^{N+1}$. If this condition is met, we return N as the VC dimension."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def VC_dimension(q):\n",
            "    N = 1\n",
            "    while True:\n",
            "        if growth_function(N + 1, q) < 2 ** (N + 1):\n",
            "            return N\n",
            "        N += 1   \n",
            "q = 2\n",
            "print(\"VC dimension of the hypothesis set: {}\".format(VC_dimension(q)))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The VC dimension is 2, which is equals to $q$, but we need to check again"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 9."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 10."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## References"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[1]\n",
            "\n",
            "[2] [Exercise 2 - homefish, GitHub](https://github.com/homefish/edX_Learning_From_Data_2017/blob/master/homework_4/homework_4_problem_2_plot_bounds.ipynb)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.5"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 1
}
