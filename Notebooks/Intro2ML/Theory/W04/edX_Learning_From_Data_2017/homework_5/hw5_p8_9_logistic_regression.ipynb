{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8 - Logistic Regression\n",
    "\n",
    "\n",
    "For the update of $w$ in gradient descent we need to compute the gradient of the error function.\n",
    "\n",
    "The error in logistic regression is given by (see slide 3, lecture 10): \n",
    "\n",
    "$e(h(\\mathbf{x}), y) = \\ln(1 + e^{-y \\mathbf{w}^T \\mathbf{x} })$\n",
    "\n",
    "\n",
    "The partial derivatives $\\frac{\\partial e}{\\partial w_k}$ are then:\n",
    "\n",
    "$\\frac{\\partial e}{\\partial w_k} = \\frac{1}{1 + e^{-y \\mathbf{w}^T \\mathbf{x} }} \\cdot e^{-y \\mathbf{w}^T \\mathbf{x} } \\cdot (-y x_k) \n",
    "= -\\frac{y \\cdot x_k}{e^{y \\mathbf{w}^T \\mathbf{x}} + 1}$\n",
    "\n",
    "with $k \\in \\{0,1,2 \\}$ (See also slide 23, lecture 9).\n",
    "\n",
    "So the gradient of $e$ is given by:\n",
    "\n",
    "$\\nabla e = [\\frac{\\partial e}{\\partial w_0},\\frac{\\partial e}{\\partial w_1}, \\frac{\\partial e}{\\partial w_2}] \n",
    "          = [-\\frac{y \\cdot x_0}{e^{y \\mathbf{w}^T \\mathbf{x}} + 1} , -\\frac{y \\cdot x_1}{e^{y \\mathbf{w}^T \\mathbf{x}} + 1} ,  -\\frac{y \\cdot x_2}{e^{y \\mathbf{w}^T \\mathbf{x}} + 1}]\n",
    "          = \\frac{-y}{e^{y \\mathbf{w}^T \\mathbf{x}} + 1}[x_0, x_1, x_2]\n",
    "          = \\frac{-y\\mathbf{x}}{e^{y \\mathbf{w}^T \\mathbf{x}} + 1}\n",
    "          $\n",
    "________\n",
    "\n",
    "We can also compute the **partial derivative** in WolframAlpha\n",
    "\n",
    "https://www.wolframalpha.com/input/?i=d%2Fdw(ln(1+%2B+exp(-y+*+w+*+x)))\n",
    "\n",
    "\n",
    "________\n",
    "\n",
    "# Problem 9\n",
    "\n",
    "Problem 9 asks us to compute the average number of epochs that are required for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross entropy error E_out over 100 runs:  0.10086614391292617\n",
      "average number of epochs:  337.43\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def problem8_9():\n",
    "    \n",
    "    RUNS = 100\n",
    "    E_out_total = 0\n",
    "    epoch_total = 0\n",
    "    \n",
    "    for run in range(RUNS):\n",
    "        # create training set with N = 100 points via separating line\n",
    "\n",
    "        # separating line,\n",
    "        # choose two random points A, B in [-1,1] x [-1,1]\n",
    "        A = np.random.uniform(-1,1,2)\n",
    "        B = np.random.uniform(-1,1,2)\n",
    "\n",
    "        # the line can be described by y = m*x + b where m is the slope\n",
    "        m = (B[1] - A[1]) / (B[0] - A[0])\n",
    "        b = B[1] - m * B[0]  \n",
    "        w_f = np.array([b, m, -1])\n",
    "\n",
    "        #-----------------------\n",
    "\n",
    "        # Pick N data points (x, y) uniformly from the box [-1,1] x [-1,1]\n",
    "        N = 100\n",
    "        x1 = np.random.uniform(-1,1,N)\n",
    "        x2 = np.random.uniform(-1,1,N)\n",
    "\n",
    "        X = np.transpose(np.array([np.ones(N), x1, x2]))           # input\n",
    "\n",
    "        # Classify these points\n",
    "        y_f = np.sign(np.dot(X, w_f))\n",
    "\n",
    "        #-----------------------\n",
    "\n",
    "        # Run logistic regression\n",
    "        # initialize weights for hypothesis with zeros\n",
    "        eta = 0.01\n",
    "        w_g = np.zeros(3)       # weight vector for hypothesis g\n",
    "\n",
    "        # start iterations\n",
    "        for t in range(10**5):\n",
    "            \n",
    "            # create permutation of data points\n",
    "            indices = list(range(N))\n",
    "            random.shuffle(indices)\n",
    "            w_old = w_g\n",
    "\n",
    "            # for each epoch\n",
    "            for index in indices:\n",
    "                xn = X[index, :]                 # pick a point\n",
    "                yn = y_f[index]\n",
    "                delta_w = -yn * xn / (1 + math.exp(yn * np.dot(w_g.T, xn)))\n",
    "\n",
    "                # update w\n",
    "                w_g = w_g - eta * delta_w\n",
    "\n",
    "            # after epoch check how much w_g changed\n",
    "            # print(\"t = \", t, \"    diff_w = \", np.linalg.norm(w_g - w_old))\n",
    "            if np.linalg.norm(w_g - w_old) < 0.01:\n",
    "                break\n",
    "\n",
    "        epoch_total += t\n",
    "\n",
    "\n",
    "        \n",
    "        # Generate 1000 test points to calculate E_out\n",
    "        N_test = 1000\n",
    "        x1_test = np.random.uniform(-1,1,N_test)                    # 1000 points\n",
    "        x2_test = np.random.uniform(-1,1,N_test)\n",
    "        X_test = np.array([np.ones(N_test), x1_test, x2_test]).T    # feature matrix\n",
    "        \n",
    "        y_f_test = np.sign(np.dot(X_test, w_f))                     # true classification\n",
    "        \n",
    "        # Calculate E_out via cross entropy error\n",
    "        E_out = 0\n",
    "        for i in range(N_test):\n",
    "            E_out += math.log(1 + math.exp(-y_f_test[i] * np.dot(X_test[i,:], w_g)))\n",
    "        \n",
    "        E_out_total += (E_out / N_test)\n",
    "    \n",
    "    E_out_avg = E_out_total / RUNS\n",
    "    epoch_avg = epoch_total / RUNS\n",
    "    \n",
    "    return (E_out_avg, epoch_avg)\n",
    "\n",
    "\n",
    "E_out_avg, epoch_avg = problem8_9()\n",
    "print(\"Average cross entropy error E_out over 100 runs: \", E_out_avg)\n",
    "print(\"average number of epochs: \", epoch_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the correct answers are **8[d]** 0.100 and **9[a]** 350."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
