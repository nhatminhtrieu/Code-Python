{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "## Problem 3\n",
    "\n",
    "### Solution\n",
    "We show that it is possible to shatter $N = 15$ points with the given hypothesis set (15 parameters and polynomials up to fourth order).\n",
    "\n",
    "### Step 1:\n",
    "\n",
    "- We first generate a list of all $2^N = 2^{15}$ dichotomies. This is done by considering the numbers $0, 1, ..., 2^{15} - 1$, and converting each of the numbers to their binary representation, i.e we first generate the strings\n",
    "\n",
    "```\n",
    "00000 00000 00000    <---- 0\n",
    "00000 00000 00001    <---- 1\n",
    "00000 00000 00010    <---- 2\n",
    "00000 00000 00011    <---- 3\n",
    "...\n",
    "11111 11111 11111    <---- 2^15 - 1\n",
    "```\n",
    "\n",
    "- These strings are then used to create the $2^{15}$ dichotomies by replacing the character '0' by the integer -1, and the character '1' is replaced by the integer +1. We then get lists of the form:\n",
    "\n",
    "```\n",
    "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
    "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1]\n",
    "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1]\n",
    "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1]\n",
    "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1]\n",
    "...\n",
    "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def get_dichotomies(N):\n",
    "\n",
    "    # each number from 0 to 2^N-1 is converted into its binary representation\n",
    "    # with length 15 (we pad zeros such that the string has length 15)\n",
    "    binaries = []\n",
    "    for i in range(2**N):\n",
    "        b = bin(i)[2:].zfill(N)\n",
    "        binaries.append([int(x) for x in b])\n",
    "\n",
    "\n",
    "    # Use the binary strings to generate 2^15 dichotomies (classifications)\n",
    "    dichotomies = []\n",
    "    for binary_list in binaries:\n",
    "        L = []\n",
    "        for x in binary_list:\n",
    "            if x == 0:\n",
    "                L.append(-1)\n",
    "            else:\n",
    "                L.append(1)\n",
    "        dichotomies.append(np.array(L))\n",
    "\n",
    "        \n",
    "    return dichotomies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "\n",
    "- We generate 15 randomly distributed points $(x_1, x_2)$ in the box $[-1,1] \\times [-1,1]$. \n",
    "\n",
    "- We create the feature matrix $\\mathbf{Z}$ (of size 15 x 15), where each row has the form $\\mathbf{z} = (1,   x_1,       x_2,     x_1^2,   x_1 x_2, \n",
    "  x^2_2, x_1^3, x^2_1 x_2, x_1 x_2^2,     x_2^3,\n",
    "  x_1^4, x_1^3 x_2, x_1^2 x_2^2, x_1 x_2^3, x_2^4)\n",
    "  $\n",
    "- For each dichotomy $\\mathbf{y_{class}}$ (which is a vector of length 15 with $+1$ and $-1$ entries) we compute a weight vector $\\mathbf{\\tilde{w}}$ via linear regression: $\\mathbf{\\tilde{w}} = (((\\mathbf{Z}^T \\mathbf{Z})^{-1} \\mathbf{Z}) \\mathbf{y_{class}})$\n",
    "- We then check if that weight vector creates the correct dichotomy via the comparison $\\mathbf{y_{class}} == \\text{sign}(\\mathbf{Z}\\mathbf{\\tilde{w}})$ .\n",
    "- If we managed to generate all $2^N = 2^{15}$ distinct dichotomies, then we have successfully shattered $N = 15$ points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct classifications: 32768\n",
      "We shattered 15 points.\n"
     ]
    }
   ],
   "source": [
    "# STEP 2\n",
    "\n",
    "\n",
    "N = 15\n",
    "dichotomies = get_dichotomies(N)\n",
    "\n",
    "\n",
    "def shatter_N_randomly_distributed_points(N, dichotomies):\n",
    "\n",
    "    # Create 15 random points in the box [-1,1] x [-1,1]\n",
    "    x1 = np.random.uniform(-1, 1, N)\n",
    "    x2 = np.random.uniform(-1, 1, N)\n",
    "\n",
    "    # feature matrix Z\n",
    "    Z = np.array([np.ones(N), x1, x2,\n",
    "                     x1**2, x1*x2, x2**2,\n",
    "                     x1**3, x1**2 * x2, x1* x2**2, x2**3,\n",
    "                      x1**4, x1**3 * x2, x1**2 * x2**2, x1 * x2**3, x2**4]).T\n",
    "\n",
    "    # see lecture 3, slide 17\n",
    "    Z_dagger = np.dot(np.linalg.inv(np.dot(Z.T, Z)), Z.T)\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    count_correct_classifications = 0\n",
    "\n",
    "    # go through all 2^N dichotomies\n",
    "    for y_class in dichotomies:    \n",
    "\n",
    "        # Use linear regression to get weight vector\n",
    "        w_tilde = np.dot(Z_dagger, y_class)\n",
    "\n",
    "        # check if weight vector generates correct dichotomy\n",
    "        if sum(y_class != np.sign(np.dot(Z, w_tilde)) ) == 0:\n",
    "            count_correct_classifications += 1\n",
    "\n",
    "\n",
    "    return count_correct_classifications    \n",
    "\n",
    "\n",
    "#------------------------\n",
    "\n",
    "num_generated_dichotomies = shatter_N_randomly_distributed_points(N, dichotomies)\n",
    "\n",
    "print(\"number of correct classifications:\", num_generated_dichotomies)\n",
    "\n",
    "if num_generated_dichotomies == 2**N:\n",
    "    print(\"We shattered\", N, \"points.\")\n",
    "else:\n",
    "    print(\"N =\", N, \"is either a break point or the points were not positioned optimally.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program shows that we can shatter 15 points.\n",
    "\n",
    "### Step 3:\n",
    "\n",
    "To gain confidence in the correctness of our program we try to shatter 15 points that are all on a line at $y = 0.7$. We suspect that it is then not possible to shatter these collinear points (see also [lecture 5](https://youtu.be/SEYAnnLazMU?t=33m1s))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct classifications: 10\n",
      "N = 15 is either a break point or the points were not positioned well.\n"
     ]
    }
   ],
   "source": [
    "# STEP 3\n",
    "\n",
    "# Check if we can shatter 15 points that are all on a line at y = 0.7\n",
    "N = 15\n",
    "dichotomies = get_dichotomies(N)\n",
    "\n",
    "\n",
    "def shatter_N_points_on_a_horizontal_line(N, dichotomies):\n",
    "\n",
    "    x1 = np.random.uniform(-1, 1, N)\n",
    "    x2 = np.array([0.7]*N)\n",
    "\n",
    "\n",
    "    Z = np.array([np.ones(N), x1, x2,\n",
    "                     x1**2, x1*x2, x2**2,\n",
    "                     x1**3, x1**2 * x2, x1* x2**2, x2**3,\n",
    "                      x1**4, x1**3 * x2, x1**2 * x2**2, x1 * x2**3, x2**4]).T\n",
    "\n",
    "\n",
    "    Z_dagger = np.dot(np.linalg.inv(np.dot(Z.T, Z)), Z.T)\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    count_correct_classifications = 0\n",
    "\n",
    "    # go through all 2^N dichotomies\n",
    "    for y_class in dichotomies:    \n",
    "\n",
    "        # Use linear regression to get weight vector\n",
    "        w_tilde = np.dot(Z_dagger, y_class)\n",
    "\n",
    "        # check if weight vector generates correct dichotomy\n",
    "        if sum(y_class != np.sign(np.dot(Z, w_tilde)) ) == 0:\n",
    "            count_correct_classifications += 1\n",
    "\n",
    "\n",
    "    return count_correct_classifications\n",
    "        \n",
    "\n",
    "# -----------------------\n",
    "\n",
    "num_generated_dichotomies = shatter_N_points_on_a_horizontal_line(N, dichotomies) \n",
    "\n",
    "print(\"number of correct classifications:\", num_generated_dichotomies)\n",
    "\n",
    "if num_generated_dichotomies == 2**N:\n",
    "    print(\"We shattered\", N, \"points.\")\n",
    "else:\n",
    "    print(\"N =\", N, \"is either a break point or the points were not positioned well.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed, we often cannot generate $2^{15}$ dichotomies with this collinear configuration of 15 points. In fact, for this collinear configuration the number of generated dichotomies appears to be much smaller than $2^{15}$.\n",
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "- Do not put all the points on the x-axis, because this means that all $x_2$ equal zero, and you get a column of zeros in the feature matrix which leads to a singular matrix when calculating the weight vector via linear regression. That's why we chose them on the line at $y = 0.7$.\n",
    "\n",
    "- Do not enter a value for N that is less than 15. It leads to a feature matrix with less rows than columns which means you have more degrees of freedom than data points.\n",
    "\n",
    "### Step 4:\n",
    "\n",
    "Let's check if we can find a weight vector for 15 points on a line if we choose the simple dichotomy $[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]$ . \n",
    "\n",
    "\n",
    "This should be possible, right? For example, we can simply put a horizontal line at $y = 5$ as a separating boundary.\n",
    "\n",
    "Let's see what linear regression finds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of generated dichotomies: 1\n",
      "number of generated dichotomies: 1\n",
      "number of generated dichotomies: 0\n",
      "number of generated dichotomies: 0\n",
      "number of generated dichotomies: 0\n",
      "number of generated dichotomies: 0\n",
      "number of generated dichotomies: 0\n",
      "number of generated dichotomies: 0\n",
      "number of generated dichotomies: 0\n",
      "number of generated dichotomies: 0\n"
     ]
    }
   ],
   "source": [
    "# STEP 4\n",
    "\n",
    "# We only consider a single dichotomy and try to find out if linear regression\n",
    "# will find a weight vector that generates this dichotomy\n",
    "dichotomies = [np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]\n",
    "N = 15\n",
    "\n",
    "# We repeat the experiment 10 times\n",
    "for i in range(10):    \n",
    "    num_generated_dichotomies = shatter_N_points_on_a_horizontal_line(N, dichotomies)\n",
    "    print(\"number of generated dichotomies:\", num_generated_dichotomies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "\n",
    "Linear regression often does not return a weight vector $\\mathbf{\\tilde{w}}$ that generates the \"simple\" dichotomy $[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]$ . It seems that it is often not able to find the \"correct\" weight vector, e.g. one that is equivalent to a horizontal line as separation boundary.\n",
    "\n",
    "One reason may be that linear regression does not try to find the correct classification but instead tries to minimize the squared errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:\n",
    "\n",
    "And finally, let's try to shatter $N = 16$ randomly distributed points which should not be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct classifications: 45110\n",
      "N = 16 is either a break point or the points were not positioned well.\n"
     ]
    }
   ],
   "source": [
    "N = 16\n",
    "dichotomies = get_dichotomies(N)\n",
    "\n",
    "num_generated_dichotomies = shatter_N_randomly_distributed_points(N, dichotomies) \n",
    "\n",
    "\n",
    "print(\"number of correct classifications:\", num_generated_dichotomies)\n",
    "\n",
    "if num_generated_dichotomies == 2**N:\n",
    "    print(\"We shattered\", N, \"points.\")\n",
    "else:\n",
    "    print(\"N =\", N, \"is either a break point or the points were not positioned well.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- For 15 randomly distributed points in the box [-1,1] x [-1,1] we managed to generate $2^{15}$ dichotomies, and thus shatter $N = 15$ points.\n",
    "- If we put the 15 points on a line at $y=0.7$, then linear regression cannot find all $2^{15}$ dichotomies.\n",
    "- It's interesting to see that for the collinear points linear regression often cannot find a weight vector for the simple dichotomy with all points classified as +1. After all linear regression doesn't try to find the correct classification but tries to minimize the squared errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
