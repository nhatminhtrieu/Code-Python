{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "\n",
    "# Problem 2\n",
    "\n",
    "We have to classify points via linear regression on a nonlinear transformed data set.\n",
    "\n",
    "\n",
    "## Import libraries and read data\n",
    "\n",
    "Let's first import libraries and read data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd        # for reading in the data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Read in training set\n",
    "\n",
    "We read in the in-sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 rows of the table:\n",
      "\n",
      "         x1        x2    y\n",
      "0 -0.779470  0.838221  1.0\n",
      "1  0.155635  0.895377  1.0\n",
      "2 -0.059908 -0.717780  1.0\n",
      "3  0.207596  0.758933  1.0\n",
      "4 -0.195983 -0.375487 -1.0\n",
      "\n",
      "The table has 35 rows and 3 columns.\n",
      "So we have N = 35 data points (x1,x2) with classification y.\n"
     ]
    }
   ],
   "source": [
    "# dataframe df\n",
    "# assign header names for each column\n",
    "# tell pandas that data is separated by whitespace\n",
    "# tell pandas that datatype is float64 \n",
    "df_train = pd.read_csv('in.dta.txt', names = [\"x1\", \"x2\", \"y\"], sep='\\s+', dtype=np.float64)\n",
    "print('The first 5 rows of the table:\\n')\n",
    "print(df_train.head(5))\n",
    "print()\n",
    "\n",
    "# alternatively read data with :\n",
    "# data = np.loadtxt('in.dta.txt', dtype=np.float64)\n",
    "# x1 = data[:,0]\n",
    "# print(x1)\n",
    "# via our mentor Jonathan @ypeels on the discussion forums\n",
    "\n",
    "\n",
    "# Examine data\n",
    "rows, col = df_train.shape\n",
    "print(\"The table has {0} rows and {1} columns.\".format(rows, col))\n",
    "print(\"So we have N = {0} data points (x1,x2) with classification y.\".format(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Linear Regression\n",
    "\n",
    "- Create feature matrix $\\mathbf{Z}$ with a nonlinear transformation.\n",
    "- Apply linear regression to get $\\mathbf{\\tilde{w}} = (Z^T Z)^{-1} Z y$, where $\\mathbf{y}$ is the vector with the classifications of each point $\\textbf{x} = (x_1, x_2)$.\n",
    "- Classify points via $\\text{sign}(\\mathbf{Z}\\mathbf{\\tilde{w}})$ which is a vector.\n",
    "- Compute the error $E_{in}$ as the fraction of points that are misclassified. This is done by counting the mismatches between $\\mathbf{y}$ and $\\text{sign}(\\mathbf{Z}\\mathbf{\\tilde{w}})$ and dividing that number by the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def problem_2_linear_regression(dataframe):\n",
    "    '''\n",
    "    Takes a pandas dataframe as test set.\n",
    "    \n",
    "    Returns the classification error and the weight vector w_tilde\n",
    "    using a linear regression hypothesis.\n",
    "    '''\n",
    "    \n",
    "    # Use data from the pandas dataframe\n",
    "    x1 = np.array(dataframe['x1'])\n",
    "    x2 = np.array(dataframe['x2'])\n",
    "    y = np.array(dataframe['y'])\n",
    "    N = dataframe.shape[0]\n",
    "    \n",
    "    # feature matrix Z\n",
    "    Z = np.array([np.ones(N), x1, x2,\n",
    "                  x1**2, x2**2, x1*x2,\n",
    "                  np.absolute(x1-x2), np.absolute(x1+x2)]).T\n",
    "\n",
    "    # see lecture 3, slide 17\n",
    "    Z_dagger = np.dot(np.linalg.inv(np.dot(Z.T, Z)), Z.T)\n",
    "\n",
    "    # Use linear regression to get weight vector\n",
    "    w_tilde = np.dot(Z_dagger, y)\n",
    "\n",
    "    # compute classification error\n",
    "    error = sum(y != np.sign(np.dot(Z, w_tilde))) / N\n",
    "    return (error, w_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute in-sample classification error $E_{in}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The in-sample classification error is E_in = 0.02857142857142857\n"
     ]
    }
   ],
   "source": [
    "# pass dataframe df_train to our function problem2_linear_regression()\n",
    "# which returns the tuple (E_in, w_tilde)\n",
    "E_in, w_tilde = problem_2_linear_regression(df_train)\n",
    "print('The in-sample classification error is E_in = {0}'.format(E_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Read in test set\n",
    "\n",
    "We read in the out-of-sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 rows of the table:\n",
      "\n",
      "         x1        x2    y\n",
      "0 -0.106006 -0.081467 -1.0\n",
      "1  0.177930 -0.345951 -1.0\n",
      "2  0.102162  0.718258  1.0\n",
      "3  0.694078  0.623397 -1.0\n",
      "4  0.023541  0.727432  1.0\n",
      "\n",
      "The table has 250 rows and 3 columns.\n",
      "So we have N = 250 data points (x1,x2) with classification y.\n"
     ]
    }
   ],
   "source": [
    "# dataframe df\n",
    "# assign header names for each column\n",
    "# tell pandas that data is separated by whitespace\n",
    "# tell pandas that datatype is float64 \n",
    "df_test = pd.read_csv('out.dta.txt', names = [\"x1\", \"x2\", \"y\"], sep='\\s+', dtype=np.float64)\n",
    "print('The first 5 rows of the table:\\n')\n",
    "print(df_test.head(5))\n",
    "print()\n",
    "\n",
    "\n",
    "# Examine data\n",
    "rows, col = df_test.shape\n",
    "print(\"The table has {0} rows and {1} columns.\".format(rows, col))\n",
    "print(\"So we have N = {0} data points (x1,x2) with classification y.\".format(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute out-of-sample classification error $E_{out}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample classification error is E_out = 0.084\n"
     ]
    }
   ],
   "source": [
    "# Use data from the pandas dataframe\n",
    "x1 = np.array(df_test['x1'])\n",
    "x2 = np.array(df_test['x2'])\n",
    "y = np.array(df_test['y'])\n",
    "N = df_test.shape[0]\n",
    "\n",
    "# feature matrix Z\n",
    "Z = np.array([np.ones(N), x1, x2,\n",
    "             x1**2, x2**2, x1*x2,\n",
    "             np.absolute(x1-x2), np.absolute(x1+x2)]).T\n",
    "\n",
    "# Compute out-of-sample error\n",
    "E_out = sum(y != np.sign(np.dot(Z, w_tilde))) / N\n",
    "print('The out-of-sample classification error is E_out = {0}'.format(E_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick answer\n",
    "\n",
    "As per problem statement we use the Euclidian distance to determine which of the possible answers is closest to our computes values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our computed values are (E_in, E_out) =  (0.028571428571428571, 0.084000000000000005) \n",
      "\n",
      "choice= (0.03, 0.08) \tEuclidian distance: 0.00424744821352\n",
      "choice= (0.03, 0.1) \tEuclidian distance: 0.0160636489107\n",
      "choice= (0.04, 0.09) \tEuclidian distance: 0.0129078365692\n",
      "choice= (0.04, 0.11) \tEuclidian distance: 0.0284009197896\n",
      "choice= (0.05, 0.1) \tEuclidian distance: 0.0267429181928\n",
      "\n",
      "We pick: (0.03, 0.08)\n"
     ]
    }
   ],
   "source": [
    "choices = [(0.03, 0.08), (0.03, 0.10), (0.04, 0.09), (0.04, 0.11), (0.05, 0.10)]\n",
    "\n",
    "computed_values = (E_in, E_out)\n",
    "\n",
    "min_distance = 2**64\n",
    "pick_choice = None\n",
    "\n",
    "print(\"Our computed values are (E_in, E_out) = \", computed_values, \"\\n\")\n",
    "\n",
    "for choice in choices:\n",
    "    distance = np.linalg.norm(np.array(choice) - np.array(computed_values))\n",
    "    if distance < min_distance:\n",
    "        min_distance = distance\n",
    "        pick_choice = choice\n",
    "    print(\"choice=\", choice, \"\\tEuclidian distance:\", distance)\n",
    "\n",
    "    \n",
    "print(\"\\nWe pick:\", pick_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "The correct answer is **2[a]** (0.03, 0.08)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
