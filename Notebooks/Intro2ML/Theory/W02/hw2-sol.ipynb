{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 2\n",
    "\n",
    "\n",
    "Hồng Thanh Hoài - 1612855\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2: Hoeﬀding Inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import các thư viện cần thiết**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tạo kết quả cho thí nghiệm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.03 s\n",
      "Wall time: 4.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_coins = 1000 # number of coins\n",
    "N = 10 # number of flipping for each coin\n",
    "mu = 0.5\n",
    "n_repeats = 100000 # run the experiment 100,000 times\n",
    "\n",
    "# Divide by @n_flipped to get nu - the fraction of heads obtained\n",
    "# at each time for each coin.\n",
    "exper = np.random.binomial(N, mu, (n_repeats, n_coins)) / N\n",
    "\n",
    "v1 = exper[:, 0]\n",
    "v_rand = exper[n_repeats - 1, np.random.choice(n_coins, size=n_repeats)]\n",
    "v_min = np.min(exper, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tính giá trị trung bình mảng các $\\nu$ của coin $c_{min}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_vmin = 0.037779\n"
     ]
    }
   ],
   "source": [
    "print('mean_vmin = %f' % (np.mean(v_min)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 1: Ta thấy kết quả gần nhất với đáp án [b] 0.01.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kiểm tra một coin có tuân theo bất đẳng thức Hoeffding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hoeffding(v, mu):\n",
    "    \"\"\"\n",
    "    Check if a coin has has a distribution of ν that satisﬁes the (single-bin) Hoeﬀding Inequality.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    v : numpy array, shape (n_repeats, 1)\n",
    "        The matrix of v's distribution of a coin at each trial.\n",
    "    mu : float\n",
    "        The real distribution of ﬂipping a fair coin.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    satisfy : boolean\n",
    "        The result after checking.\n",
    "    \"\"\"\n",
    "    # Init satisfy\n",
    "    satisfy = True\n",
    "    for epsilon in np.arange(0.01, 0.5, 0.01):\n",
    "        if np.mean(abs(v - mu) > epsilon) > 2*exp(-2*N*epsilon**2):\n",
    "            satisfy = False\n",
    "            break\n",
    "    return satisfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ta kiểm tra $c_{1}$, $c_{rand}$ và $c_{min}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check satisfying hoeffding inequality\n",
      "c1: \tTrue\n",
      "c_rand: True\n",
      "c_min: \tFalse\n"
     ]
    }
   ],
   "source": [
    "print('check satisfying hoeffding inequality')\n",
    "print('c1: \\t%s' % (check_hoeffding(v1, mu)))\n",
    "print('c_rand: %s' % (check_hoeffding(v_rand, mu)))\n",
    "print('c_min: \\t%s' % (check_hoeffding(v_min, mu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 2: Ta thấy kết quả là đáp án [d] $c_{1}$ and $c_{rand}$.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4: Error and Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 3:**</font>\n",
    "Đề bài yêu cầu tìm xác suất lỗi khi $h$ xấp xỉ $y$ (có nhiễu).\n",
    "Ta có $\\mu$ là xác suất lỗi khi $h$ xấp xỉ một hàm tất định.\n",
    "Có hai trường hợp xảy ra khi có nhiễu:\n",
    "+ $h=f(x)$ (_hypothesis_ h được chấp nhận) nhưng $y\\neq f(x)$, xác suất là: $(1-\\mu)*(1-\\lambda)$\n",
    "+ $h\\neq f(x)$ nhưng $y=f(x)$, xác suất là: $\\mu*\\lambda$  \n",
    "\n",
    "Vậy, xác suất lỗi khi $h$ xấp xỉ $y$ là: $P=(1-\\mu)*(1-\\lambda)+\\mu*\\lambda$  \n",
    "<font color=blue>**Do đó, đán án đúng là [e] $(1-\\lambda)*(1-\\mu)+\\mu*\\lambda$.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 4:**</font>\n",
    "Tại $\\lambda=0.5$, giá trị $\\mu$ trong $P$ sẽ bị triệt tiêu nên $h$ sẽ độc lập với $\\mu$. Khi đó, nếu $h$ dự đoán đúng $100\\%$ thì vẫn sẽ có $50\\%$ sai (do nhiễu). Ngược lại, nếu $h$ dự đoán sai $100\\%$ thì vẫn sẽ $50\\%$ đúng.  \n",
    "<font color=blue>**Do đó, đáp án đúng là [b] 0.5.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-7: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm phát sinh ra `target_w`, vector tham số của $f$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_w():\n",
    "    \"\"\"\n",
    "    Generates target_w from two random, uniformly distributed points in [-1, 1] x [-1, 1].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \"\"\"\n",
    "    # Generate two points from a uniform distribution over [-1, 1]x[-1, 1]\n",
    "    p1 = np.random.uniform(-1, 1, 2)\n",
    "    p2 = np.random.uniform(-1, 1, 2)\n",
    "    # Compute the target W from these two points\n",
    "    target_w = np.array([p1[1]*p2[0] - p1[0]*p2[1], p2[1] - p1[1], p1[0] - p2[0]]).reshape((-1, 1))\n",
    "    \n",
    "    return target_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm phát sinh ra tập dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, target_w):\n",
    "    \"\"\"\n",
    "    Generates a data set by generating random inputs and then using target_w to generate the \n",
    "    corresponding outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    noise : float\n",
    "        The percentage of noise in data set.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    ys : numpy array, shape (N, 1)\n",
    "        The vector of outputs.        \n",
    "    \"\"\"\n",
    "    bad_data = True # `bad_data = True` means: data contain points on the target line \n",
    "                    # (this rarely happens, but just to be careful)\n",
    "                    # -> y's of these points = 0 (with np.sign); \n",
    "                    #    we don't want this (y's of data must be -1 or 1)\n",
    "                    # -> re-generate data until `bad_data = False`\n",
    "    \n",
    "    while bad_data == True:\n",
    "        X = np.random.uniform(-1, 1, (N, 2))\n",
    "        X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "        ys = np.sign(np.dot(X, target_w))\n",
    "        if (0 not in ys): # Good data\n",
    "            bad_data = False\n",
    "    \n",
    "    return X, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm chạy Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3: Generalization Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LR(X, ys):\n",
    "    \"\"\"\n",
    "    Runs PLA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    ys : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of g.\n",
    "    \"\"\"\n",
    "    X_dagger = np.dot(np.linalg.pinv(np.dot(X.T, X)), X.T)\n",
    "    w = np.dot(X_dagger, ys)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.83941761, -0.24939166],\n",
       "       [ 1.        ,  0.85613256,  0.61430973]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_w = generate_target_w()\n",
    "X, ys = generate_data(2, target_w)\n",
    "w = run_LR(X, ys)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm chạy cho câu 5 và câu 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_LR_5_6():\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of training examples.\n",
    "    noise : float\n",
    "        The percentage of noise in data set.\n",
    "    \"\"\"\n",
    "    num_runs = 1000\n",
    "    # The average in-sample error of g - the final hypothesis picked by Linear Regression\n",
    "    avg_ein = 0.0\n",
    "    # The average out-of-sample error of g\n",
    "    avg_eout = 0.0\n",
    "    # Number of in-sample points\n",
    "    n_in = 100\n",
    "    # Number of out-sample points (estimation purpose)\n",
    "    n_out = 1000\n",
    "    \n",
    "    for r in range(num_runs):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        # Generate training set\n",
    "        X_in, y_in = generate_data(n_in, target_w)\n",
    "        # Generate out-of-sample dataset\n",
    "        X_out, y_out = generate_data(n_out, target_w)\n",
    "        \n",
    "        # Run Linear Regression to pick g\n",
    "        w = run_LR(X_in, y_in)\n",
    "        \n",
    "        # Predict on training set with found w\n",
    "        predictions_in = np.dot(X_in, w)\n",
    "        # Predict on out-of-sample set with found w\n",
    "        predictions_out = np.dot(X_out, w)\n",
    "        \n",
    "        # Compute binary error between y_in/ y_out - correct output & predictions\n",
    "        ein = np.mean(y_in != np.sign(predictions_in))\n",
    "        eout = np.mean(y_out != np.sign(predictions_out))\n",
    "        \n",
    "        # Update average error\n",
    "        avg_ein += (ein * 1.0 / num_runs)\n",
    "        avg_eout += (eout * 1.0 / num_runs)\n",
    "    \n",
    "    # Print results\n",
    "    print('avg_ein = %f' % (avg_ein))\n",
    "    print('avg_eout = %f' % (avg_eout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_ein = 0.038040\n",
      "avg_eout = 0.047869\n"
     ]
    }
   ],
   "source": [
    "main_LR_5_6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 5: Ta thấy kết quả gần nhất với đáp án [c] 0.01.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 6: Ta thấy kết quả gần nhất với đáp án [c] 0.01.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dùng Linear Regression để tìm `w` khởi tạo cho PLA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_PLA(X, ys):\n",
    "    \"\"\"\n",
    "    Runs PLA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    ys : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    num_iterations : int\n",
    "        The number of iterations PLA takes to converge.\n",
    "    \"\"\"\n",
    "    # Init w using Linear Regression\n",
    "    w = run_LR(X, ys)\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        iteration += 1\n",
    "        # Compute sign for each input vector with current w\n",
    "        h = np.sign(np.dot(X, w))\n",
    "        \n",
    "        # Find misclassified if existed\n",
    "        for i in range(0, X.shape[0]):\n",
    "            if h[i] != ys[i]:\n",
    "                change = X[i]*ys[i]\n",
    "                # Change current w to make X[i] classified\n",
    "                w = w + change.reshape((-1, 1))\n",
    "                break\n",
    "        \n",
    "        # Check if converged\n",
    "        if np.array_equal(h, ys) == True:\n",
    "            break\n",
    "    \n",
    "    return iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm main (PLA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_PLA(N):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of training examples.\n",
    "    \"\"\"\n",
    "    num_runs = 1000\n",
    "    # The average number of iterations PLA takes to converge\n",
    "    avg_num_iterations = 0.0\n",
    "    \n",
    "    for r in range(num_runs):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        \n",
    "        # Generate training set\n",
    "        X, ys = generate_data(N, target_w)\n",
    "        \n",
    "        # Run PLA to completely separates all the in-sample points\n",
    "        num_iterations = run_PLA(X, ys)\n",
    "        \n",
    "        # Update average num_iterations\n",
    "        avg_num_iterations += (num_iterations * 1.0 / num_runs)\n",
    "    \n",
    "    # Print results\n",
    "    print('avg_num_iterations = %f' % (avg_num_iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chạy với $N=10$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 7.175000\n"
     ]
    }
   ],
   "source": [
    "main_PLA(N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 7: Ta thấy kết quả gần nhất với đáp án [a] 1.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-10: Nonlinear Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm phát sinh tập huấn luyện với độ lỗi `noise`, `target function` là $f(x_{1}, x_{2})=sign(x_{1}^2+x_{1}^2-0.6)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_with_noise(N, noise):\n",
    "    \"\"\"\n",
    "    Generates a data set by generating random inputs and then using target_w to generate the \n",
    "    corresponding outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    noise : float\n",
    "        The percentage of noise in data set.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    ys : numpy array, shape (N, 1)\n",
    "        The vector of outputs.        \n",
    "    \"\"\"\n",
    "    bad_data = True # `bad_data = True` means: data contain points on the target line \n",
    "                    # (this rarely happens, but just to be careful)\n",
    "                    # -> y's of these points = 0 (with np.sign); \n",
    "                    #    we don't want this (y's of data must be -1 or 1)\n",
    "                    # -> re-generate data until `bad_data = False`\n",
    "    \n",
    "    while bad_data == True:\n",
    "        X = np.random.uniform(-1, 1, (N, 2))\n",
    "        X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "        ys = np.sign(X[:, 1]**2 + X[:, 2]**2 - 0.6)\n",
    "        if (0 not in ys): # Good data\n",
    "            bad_data = False\n",
    "            \n",
    "    # Generate simulated noise by ﬂipping the sign of the output randomly\n",
    "    indices = np.random.choice(np.arange(N), size=int(noise*N), replace=False)\n",
    "    ys[indices] = -ys[indices]\n",
    "    \n",
    "    return X, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm chuyển từ mảng `X` gồm các vector input $x$ ban đầu sang mảng `Z` gồm các vector đặc trưng $z$. Theo đề, $z = [1, x_1, x_2, x_1x_2, x_1^2, x_2^2]^T$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_nonlinear(X, ys):\n",
    "    \"\"\"\n",
    "    Transform the N = 1000 training data into the nonlinear feature vector.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    noise : float\n",
    "        The percentage of noise in data set.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Z : numpy array, shape (N, 6)\n",
    "        The matrix of data after transforming (each row corresponds to an input vector);\n",
    "        the first column of this matrix is all ones.\n",
    "    ys : numpy array, shape (N, 1)\n",
    "        The vector of correct outputs.     \n",
    "    w : numpy array, shape (6, 1)\n",
    "        The average w that found\n",
    "    \"\"\"\n",
    "    x1x2 = np.array([X[:, 1]*X[:, 2]])\n",
    "    # x1 square\n",
    "    x1sqr = np.array([X[:, 1]**2])\n",
    "    # x2 square\n",
    "    x2sqr = np.array([X[:, 2]**2])\n",
    "    Z = np.concatenate((X, x1x2.T, x1sqr.T, x2sqr.T), axis=1)\n",
    "    print(Z.shape)\n",
    "    return Z, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm dùng cho câu 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_LR_8(N, noise):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X   : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    ys  : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    w   : numpy array\n",
    "        The vector of parameters of g.\n",
    "    \"\"\"\n",
    "    num_runs = 1000\n",
    "    # The average test error of g - the final hypothesis picked by Linear Regression\n",
    "    avg_err = 0.0\n",
    "    \n",
    "    for r in range(num_runs):\n",
    "        # Generate training set with noise & specific target function\n",
    "        X, ys = generate_data_with_noise(N, noise)\n",
    "        \n",
    "        # Run Linear Regression to pick g if not in the input\n",
    "        w = run_LR(X, ys)\n",
    "        \n",
    "        # Prediction on X with w found\n",
    "        predictions = np.dot(X, w)\n",
    "        \n",
    "        # Compute binary error between ys - correct output & predictions\n",
    "        err = np.mean(ys != np.sign(predictions))\n",
    "        \n",
    "        # Update average error\n",
    "        avg_err += (err * 1.0 / num_runs)\n",
    "    \n",
    "    # Print results\n",
    "    print('avg_err = %f' % (avg_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chạy với $N=1000$, $noise=0.1$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_err = 0.505361\n"
     ]
    }
   ],
   "source": [
    "main_LR_8(N=1000, noise=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 8: Ta thấy kết quả gần nhất với đáp án [d] 0.5.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ta tìm `w` khi chuyển sang _nonlinear feature vector_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "[-9.91831772e-01 -1.06510832e-03 -5.41491694e-03 -1.74426849e-02\n",
      "  1.55373419e+00  1.56273427e+00]\n"
     ]
    }
   ],
   "source": [
    "num_runs = 100\n",
    "avg_w = 0.0\n",
    "N = 1000\n",
    "noise = 0.1\n",
    "\n",
    "for r in range(num_runs):\n",
    "    X, ys = generate_data_with_noise(N, noise)\n",
    "    Z, ys = transform_to_nonlinear(X, ys)\n",
    "    avg_w += (run_LR(Z, ys) * 1.0 / num_runs)\n",
    "\n",
    "print(avg_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ta so sánh độ lỗi của `w` tìm được với `w` ở các đáp án**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "(1000, 6)\n",
      "avg_err_w_found = 0.123084\n",
      "a: 0.142788\t b: 0.348045\t c: 0.348779\t d: 0.408101\t e: 0.474419\t\n"
     ]
    }
   ],
   "source": [
    "num_runs = 1000\n",
    "N = 1000\n",
    "noise = 0.1\n",
    "\n",
    "avg_err_w_found = 0.0\n",
    "avg_err_w_a = 0.0\n",
    "avg_err_w_b = 0.0\n",
    "avg_err_w_c = 0.0\n",
    "avg_err_w_d = 0.0\n",
    "avg_err_w_e = 0.0\n",
    "\n",
    "w_found = avg_w\n",
    "w_a = np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5])\n",
    "w_b = np.array([-1, -0.05, 0.08, 0.13, 1.5, 15])\n",
    "w_c = np.array([-1, -0.05, 0.08, 0.13, 15, 1.5])\n",
    "w_d = np.array([-1, -1.5, 0.08, 0.13, 0.05, 0.05])\n",
    "w_e = np.array([-1, -0.05, 0.08, 1.5, 0.15, 0.15])\n",
    "    \n",
    "for r in range(num_runs): \n",
    "    X, ys = generate_data_with_noise(N, noise)\n",
    "    Z, ys = transform_to_nonlinear(X, ys)\n",
    "    \n",
    "    # Predict on Z with w found\n",
    "    predictions_w_found = np.dot(Z, w_found)\n",
    "    # Predict on Z with w_a\n",
    "    predictions_w_a = np.dot(Z, w_a)\n",
    "    # Predict on Z with w_b\n",
    "    predictions_w_b = np.dot(Z, w_b)\n",
    "    # Predict on Z with w_c\n",
    "    predictions_w_c = np.dot(Z, w_c)\n",
    "    # Predict on Z with w_d\n",
    "    predictions_w_d = np.dot(Z, w_d)\n",
    "    # Predict on Z with w_e\n",
    "    predictions_w_e = np.dot(Z, w_e)\n",
    "        \n",
    "    # Compute binary error between ys - correct output & predictions\n",
    "    err_w_found = np.mean(ys != np.sign(predictions_w_found))\n",
    "    err_w_a = np.mean(ys != np.sign(predictions_w_a))\n",
    "    err_w_b = np.mean(ys != np.sign(predictions_w_b))\n",
    "    err_w_c = np.mean(ys != np.sign(predictions_w_c))\n",
    "    err_w_d = np.mean(ys != np.sign(predictions_w_d))\n",
    "    err_w_e = np.mean(ys != np.sign(predictions_w_e))\n",
    "        \n",
    "    # Update average error\n",
    "    avg_err_w_found += (err_w_found * 1.0 / num_runs)\n",
    "    avg_err_w_a += (err_w_a * 1.0 / num_runs)\n",
    "    avg_err_w_b += (err_w_b * 1.0 / num_runs)\n",
    "    avg_err_w_c += (err_w_c * 1.0 / num_runs)\n",
    "    avg_err_w_d += (err_w_d * 1.0 / num_runs)\n",
    "    avg_err_w_e += (err_w_e * 1.0 / num_runs)\n",
    "    \n",
    "# Print results\n",
    "print('avg_err_w_found = %f' % (avg_err_w_found))\n",
    "print('a: %f\\t b: %f\\t c: %f\\t d: %f\\t e: %f\\t' % (avg_err_w_a, avg_err_w_b, avg_err_w_c, avg_err_w_d, avg_err_w_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 9: Ta thấy kết quả gần nhất với đáp án [a] $g(x_{1},x_{2}) = sign(−1−0.05x_{1} + 0.08x_{2} + 0.13x_{1}x_{2} + 1.5x_{1}^2 + 1.5x_{2}^2)$.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$E_{out}$ với `w` tìm được ở câu 9 (yêu cầu của câu 10) chính là giá trị của `avg_err_w_found` ở block code phía trên:**\n",
    "**$E_{out}\\approx 0.1$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 10: Ta thấy kết quả gần nhất với đáp án [b] 0.1.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tham khảo: \n",
    "1. [Linear Regression](https://machinelearningcoban.com/2016/12/28/linearregression/)\n",
    "2. [NumPy v1.16 Manual](https://docs.scipy.org/doc/numpy/)\n",
    "3. [Markdown Cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
