{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab03: Logistic Regression.\n",
    "\n",
    "- Student ID: 21127112\n",
    "- Student name: Triệu Nhật Minh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to do your homework**\n",
    "\n",
    "\n",
    "You will work directly on this notebook; the word `TODO` indicate the parts you need to do.\n",
    "\n",
    "You can discuss ideas with classmates as well as finding information from the internet, book, etc...; but *this homework must be your*.\n",
    "\n",
    "**How to submit your homework**\n",
    "\n",
    "Before submitting, rerun the notebook (`Kernel` ->` Restart & Run All`).\n",
    "\n",
    "Then create a folder named `ID` (for example, if your ID is 1234567, then name the folder `1234567`). Copy file notebook to this folder, compress and submit it on moodle.\n",
    "\n",
    "**Contents:**\n",
    "- Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml \n",
    "X, y = fetch_openml('mnist_784', return_X_y=True, parser='auto') # FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we basically have 70000 samples with each sample having 784 features - pixels in this case and a label - the digit the image represent.\n",
    "\n",
    "Let’s play around and see if we can extract any features from the pixels that can be more informative. First I’d like to know more about average intensity - that is the average value of a pixel in an image for the different digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels=np.unique(y)\n",
    "# # print(labels)\n",
    "# n_label=np.unique(y).shape[0]\n",
    "# l_means=np.zeros(shape=n_label,dtype=float) #array stores average intensity for each label\n",
    "\n",
    "# #TODO compute average intensity for each label\n",
    "# l_counts = np.zeros(shape=n_label,dtype=int)\n",
    "# print(y[2])\n",
    "# print(n_label)\n",
    "# for i in range(len(X)):\n",
    "    \n",
    "#     l_counts[int(y[i])]+=1\n",
    "# print(l_counts)\n",
    "# for i in range(len(X)):\n",
    "#     sum = X.iloc[i].sum()\n",
    "#     avg_i=sum/l_counts[int(y[i])]\n",
    "#     l_means[int(y[i])]=avg_i\n",
    "# print(l_means)\n",
    "# # print(l_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
      "4\n",
      "10\n",
      "[6903 7877 6990 7141 6824 6313 6876 7293 6825 6958]\n",
      "[7.94118499 2.18852355 5.54692418 4.81949307 4.28355803 4.20703311\n",
      " 6.08391507 3.6360894  6.64234432 4.28830124]\n"
     ]
    }
   ],
   "source": [
    "labels=np.unique(y)\n",
    "print(labels)\n",
    "n_label=np.unique(y).shape[0]\n",
    "l_means=np.zeros(shape=n_label,dtype=float) #array stores average intensity for each label\n",
    "#TODO compute average intensity for each label\n",
    "l_counts = np.zeros(shape=n_label,dtype=int)\n",
    "print(y[2])\n",
    "print(n_label)\n",
    "for i in range(len(X)):\n",
    "    \n",
    "    l_counts[int(y[i])]+=1\n",
    "print(l_counts)\n",
    "for i in range(len(X)):\n",
    "    sum = X.iloc[i].sum()\n",
    "    avg_i=sum/l_counts[int(y[i])]\n",
    "    l_means[int(y[i])]=avg_i\n",
    "    \n",
    "print(l_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the average intensity using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(labels,l_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are some differences in intensity. The digit “1” is the less intense while the digit “0” is the most intense. So this new feature seems to have some predictive value if you wanted to know if say your digit is a “1” or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "#TODO compute average intensity for each data sample\n",
    "intensity=np.zeros(shape=y.shape,dtype=float)\n",
    "for i in range(len(X)):\n",
    "    sum = X.iloc[i].sum()\n",
    "    avg_i=sum/len(X.iloc[i])\n",
    "    intensity[i]=avg_i\n",
    "print(intensity.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes people really do not know what are they doing. I am not an exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "# X_flip=np.flip(X, axis=0)\n",
    "# symmetry= np.mean((X-X_flip),axis=1)\n",
    "# print(symmetry.shape)\n",
    "\n",
    "# If X is a 1D array\n",
    "X_numpy = X.values\n",
    "X_flip = np.flip(X_numpy, axis=0)\n",
    "symmetry = np.mean((X - X_flip), axis=1)\n",
    "print(symmetry.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I called this feature \"symmetry\" (though it's not \"symmetry\" at all). Use visualization method to understand why this feature work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new trainning data will have 70000 samples and 2 features: intensity, symmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000,)\n"
     ]
    }
   ],
   "source": [
    "#TODO create X_new by horizontal stack intensity and symmetry\n",
    "\n",
    "X_new=np.hstack((intensity,symmetry))\n",
    "\n",
    "print(X_new.shape) #it should be (70000,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually logistic regression is a good first choice for classification. In this homework we use logistic regression for classifying digit 1 images and not digit 1 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data\n",
    "First normalize data using Z-score normalization\n",
    "- **TODO: Study about Z-score normalization**\n",
    "- **TODO: Why should we normalize data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000,)\n"
     ]
    }
   ],
   "source": [
    "#TODO: normalize X_new\n",
    "\n",
    "X_new=(X_new-np.mean(X_new))/np.std(X_new)\n",
    "print(X_new.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280000, 2)\n",
      "(70000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_new = X_new.reshape(-1, 1)  # Reshape X_new to have two dimensions\n",
    "X_new = np.hstack((np.ones((len(X_new), 1)), X_new))  # Now you can stack\n",
    "# X_new = np.hstack((np.ones((len(X_new), 1)), X_new)) #stack 1s column as usual\n",
    "y_new=y.astype(int)\n",
    "y_new[y_new != 1] = 0 # digit 1 -> class 1, other digits -> class 0\n",
    "# y_new=y_new.reshape(-1,1)\n",
    "y_new = y_new.values.reshape(-1, 1)\n",
    "print (X_new.shape)\n",
    "print (y_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [280000, 70000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MINH\\Downloads\\Coding\\Code-Python\\Notebooks\\Intro2ML\\Lab03\\Lab03\\21127112.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MINH/Downloads/Coding/Code-Python/Notebooks/Intro2ML/Lab03/Lab03/21127112.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_X, test_X, train_y, test_y \u001b[39m=\u001b[39m train_test_split(X_new, y_new, test_size\u001b[39m=\u001b[39;49m \u001b[39mint\u001b[39;49m(\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m3\u001b[39;49m\u001b[39m*\u001b[39;49mX\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MINH/Downloads/Coding/Code-Python/Notebooks/Intro2ML/Lab03/Lab03/21127112.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(train_X\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MINH/Downloads/Coding/Code-Python/Notebooks/Intro2ML/Lab03/Lab03/21127112.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(train_y\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\MINH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MINH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2646\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2643\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2644\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2646\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2648\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2649\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2650\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2651\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MINH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:453\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \n\u001b[0;32m    436\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 453\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    454\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\MINH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [280000, 70000]"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X_new, y_new, test_size= int(1/3*X.shape[0]))\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function and derivative of the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(x):\n",
    "    \"\"\"compute the sigmoid activation value for a given input\"\"\"\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "def sigmoid_deriv(x):\n",
    "    '''compute the derivative of the sigmoid function ASSUMING\n",
    "    that the input ‘x‘ has already been passed through the sigmoid\n",
    "    activation function'''\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_h(W, X):\n",
    "    \"\"\"\n",
    "    Compute output: Take the dot product between our features ‘X‘ and the weight\n",
    "    matrix ‘W‘, then pass this value through our sigmoid activation function \n",
    "    \"\"\"\n",
    "    return sigmoid_activation(X.dot(W))\n",
    "def predict(W, X):\n",
    " \n",
    "    '''Take the dot product between our features and weight matrix, \n",
    "       then pass this value through our sigmoid activation'''\n",
    "    #........\n",
    "    preds=sigmoid_activation(X.dot(W))\n",
    "    # apply a step function to threshold the outputs to binary\n",
    "    # class labels\n",
    "    preds[preds <= 0.5] = 0\n",
    "    preds[preds > 0] = 1\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss Function: Average negative log likelihood**\n",
    "$$\\mathcal{L}=\\dfrac{1}{N} \\sum_{i=1}^{N} -\\left(y^{i}\\ln h_{\\mathbf{w}}\\left(\\mathbf{x}^{i}\\right)+\\left(1-y^{i}\\right)\\ln \\left(1-h_{\\mathbf{w}}\\left(x^{i}\\right)\\right)\\right) $$\n",
    "\n",
    "\n",
    "$$\\text{Sigmoid Activation: } z= \\sigma \\left(h\\right)= \\dfrac{1}{1+e^{-h}}$$\n",
    "\n",
    "$$\\text{Cross-entropy: } J(w)=-\\left({ylog(z)+(1-y)log(1-z)}\\right)$$\n",
    "\n",
    "$$\\text{Chain rule: } \\dfrac{\\partial J(w)}{\\partial w}=\\dfrac{\\partial J(w)}{\\partial z} \\dfrac{\\partial z}{\\partial h}\\dfrac{\\partial h}{\\partial w}  $$\n",
    "\n",
    "$$\\dfrac{\\partial J(w)}{\\partial z}=-\\left(\\dfrac{y}{z}-\\dfrac{1-y}{1-z}\\right)=\\dfrac{z-y}{z(1-z)}$$\n",
    "\n",
    "$$\\dfrac{\\partial z}{\\partial h}=z(1-z)$$\n",
    "\n",
    "$$\\dfrac{\\partial h}{\\partial w}=X$$\n",
    "\n",
    "$$\\dfrac{\\partial J(w)}{\\partial w}=X^T(z-y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(train_X, error):\n",
    "    \"\"\"\n",
    "    This is the gradient descent update of \"average negative loglikelihood\" loss function. \n",
    "    In lab02 our loss function is \"sum squared error\".\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(W,train_X, train_y, learning_rate, num_epochs, losses):\n",
    "    for epoch in np.arange(0, num_epochs):\n",
    "        h=compute_h(W,train_X)\n",
    "        error = h - train_y\n",
    "        loss = np.mean(- train_y * np.log(h) - (1 - train_y) * np.log(1 - h))\n",
    "        losses.append(loss)\n",
    "        gradient=compute_gradient(h, error)\n",
    "        W += -learning_rate * gradient\n",
    "        if ((epoch+1)%1000==0): print ('Epoch %d, loss %.3f' %(epoch+1, loss))\n",
    "        \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W = np.random.randn(train_X.shape[1], 1)\n",
    "losses=[]\n",
    "num_epochs=40000\n",
    "learning_rate=0.01\n",
    "W=train(W,train_X, train_y, learning_rate, num_epochs , losses)\n",
    "x_preds=predict(W ,train_X)\n",
    "train_err = np.mean(x_preds != train_y) * 100\n",
    "print ('=' * 50)\n",
    "print ('Train err of final w: ', train_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(W, train_X)\n",
    "print(classification_report(train_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(W, test_X)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Comment on the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
